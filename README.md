# DeployLLM-Flask-Nginx-Gunicorn

![Deploy LLM Flask App](https://raw.githubusercontent.com/extergeist/DeployLLM-Flask-Nginx-Gunicorn/main/images/thumbnail.png)

This repository supplements my complete tutorial series on deploying a production-ready Flask application with local LLM inference using a 4B LLM.

## ðŸ“º Video Tutorial Series

- **[Part 1: Server Setup](https://youtu.be/fNUC0xbVa1c?si=r-lJJhWUzmFAoe0M)** - Ubuntu server configuration and environment preparation
- **[Part 2: Flask Deployment](https://youtu.be/nuZCUp3gGNY?si=KFMr6xqH6Pb1Av1l)** - Flask app, Nginx, Gunicorn, and GPT4All integration

**[ðŸ“Œ Full Playlist](https://www.youtube.com/playlist?list=PLxWZSlEg-oTU0AeMO9TiqcVvWzJ15wiV1)**


## ðŸŽ¯ Use Cases

- Private chatbot for sensitive business data
- Educational AI projects
- Prototyping AI applications
- Learning production deployment patterns
- Cost-effective AI solutions

- ## ðŸ“¸ Demo

![Web Chat Interface](https://raw.githubusercontent.com/extergeist/DeployLLM-Flask-Nginx-Gunicorn/main/images/demo.png)

---

**Note**: While this tutorial uses GPT4All as an example, the deployment approach works with any local language model. Feel free to adapt it for your specific needs!
